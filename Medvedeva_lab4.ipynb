{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/morisdibil/notebook1b71ce664d?scriptVersionId=91377046\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"! pip install datasets\n! pip install transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('yahoo_answers_topics') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import (ElectraTokenizer, ElectraForSequenceClassification,\n                          get_scheduler, pipeline, ElectraForMaskedLM, ElectraModel)\n\nimport torch\n\nfrom torch.utils.data import DataLoader\nfrom datasets import load_metric\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nMODEL_NAME = \"google/electra-small-generator\"\nTOKENIZER_NAME = \"google/electra-small-generator\"","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:31:22.168264Z","iopub.execute_input":"2022-03-27T09:31:22.169358Z","iopub.status.idle":"2022-03-27T09:31:30.059893Z","shell.execute_reply.started":"2022-03-27T09:31:22.169317Z","shell.execute_reply":"2022-03-27T09:31:30.059118Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"fill_mask = pipeline(\n    \"fill-mask\",\n    model=MODEL_NAME,\n    tokenizer=MODEL_NAME\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:59:34.596139Z","iopub.execute_input":"2022-03-27T13:59:34.596891Z","iopub.status.idle":"2022-03-27T13:59:38.952263Z","shell.execute_reply.started":"2022-03-27T13:59:34.596851Z","shell.execute_reply":"2022-03-27T13:59:38.951524Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"ex = [\"Why don't you ask [MASK]?\",\n      \"What is [MASK]\",\n      \"Let's talk about [MASK] physics\"]\n\nfor i in ex:\n    print(\n    fill_mask(i)[0]['sequence']\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:59:56.067826Z","iopub.execute_input":"2022-03-27T13:59:56.068081Z","iopub.status.idle":"2022-03-27T13:59:57.317327Z","shell.execute_reply.started":"2022-03-27T13:59:56.06805Z","shell.execute_reply":"2022-03-27T13:59:57.316339Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"why don't you ask me?\nwhat is?\nlet's talk about quantum physics\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model downloading and data preparation","metadata":{}},{"cell_type":"code","source":"from transformers import ElectraForSequenceClassification, ElectraConfig, ElectraTokenizer\n\nconfig = ElectraConfig()\ntokenizer = ElectraTokenizer.from_pretrained(TOKENIZER_NAME)\nmodel = ElectraForSequenceClassification.from_pretrained(TOKENIZER_NAME)\n\nmodel.classifier.dense = torch.nn.Linear(256, 64)\nmodel.classifier.out_proj = torch.nn.Sequential(\n    torch.nn.LeakyReLU(),\n    torch.nn.Linear(64, 10))\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:42:41.293394Z","iopub.execute_input":"2022-03-27T09:42:41.293951Z","iopub.status.idle":"2022-03-27T09:42:44.622557Z","shell.execute_reply.started":"2022-03-27T09:42:41.293914Z","shell.execute_reply":"2022-03-27T09:42:44.621663Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.bias', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight', 'generator_lm_head.weight']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"ElectraForSequenceClassification(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n      (position_embeddings): Embedding(512, 128)\n      (token_type_embeddings): Embedding(2, 128)\n      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): ElectraClassificationHead(\n    (dense): Linear(in_features=256, out_features=64, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Sequential(\n      (0): LeakyReLU(negative_slope=0.01)\n      (1): Linear(in_features=64, out_features=10, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\n\nids = np.random.randint(0, high=1400000, size=80000)\nx = np.array(dataset['train']['question_title'])[ids]\ny = np.array(dataset['train']['topic'])[ids]\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:45:03.205648Z","iopub.execute_input":"2022-03-27T09:45:03.205912Z","iopub.status.idle":"2022-03-27T09:45:06.879759Z","shell.execute_reply.started":"2022-03-27T09:45:03.205883Z","shell.execute_reply":"2022-03-27T09:45:06.879015Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nCounter(y)\n# classes are almost balanced","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:46:49.461957Z","iopub.execute_input":"2022-03-27T09:46:49.462628Z","iopub.status.idle":"2022-03-27T09:46:49.48787Z","shell.execute_reply.started":"2022-03-27T09:46:49.462592Z","shell.execute_reply":"2022-03-27T09:46:49.487156Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Counter({2: 7956,\n         8: 7887,\n         3: 7971,\n         0: 8148,\n         4: 8003,\n         9: 7878,\n         5: 8104,\n         7: 7927,\n         6: 8111,\n         1: 8015})"},"metadata":{}}]},{"cell_type":"code","source":"x_train = tokenizer(x_train.tolist(), padding=\"max_length\", truncation=True, return_tensors='pt')\nx_val = tokenizer(x_val.tolist(), padding=\"max_length\", truncation=True, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:47:26.198586Z","iopub.execute_input":"2022-03-27T09:47:26.198843Z","iopub.status.idle":"2022-03-27T09:48:18.962028Z","shell.execute_reply.started":"2022-03-27T09:47:26.198813Z","shell.execute_reply":"2022-03-27T09:48:18.961282Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass EDataset(Dataset):\n    def __init__(self, x, y):\n        super().__init__()\n        self.x = x\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, index):\n        input_ids = self.x['input_ids'][index]\n        token_type_ids = self.x['token_type_ids'][index]\n        att_mask = self.x['attention_mask'][index]\n        y_out = self.y[index]\n        \n        out = {'input_ids': input_ids,\n               'token_type_ids': token_type_ids,\n               'attention_mask': att_mask}\n\n        return out, y_out\n\ntrain_dataset = EDataset(x_train, y_train)\nval_dataset = EDataset(x_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:48:36.815775Z","iopub.execute_input":"2022-03-27T09:48:36.81604Z","iopub.status.idle":"2022-03-27T09:48:36.823556Z","shell.execute_reply.started":"2022-03-27T09:48:36.81601Z","shell.execute_reply":"2022-03-27T09:48:36.822547Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport numpy as np\nfrom sklearn.metrics import f1_score\n\ndef fit_epoch(model, train_loader, criterion, optimizer):\n    model.train()\n    running_loss = []\n    acc = []\n    for inputs, labels in train_loader:\n        input_ids = inputs['input_ids'].to(device)\n        attention_mask = inputs['attention_mask'].to(device)\n        token_type_ids = inputs['token_type_ids'].to(device)\n        labels = labels.to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        loss = criterion(outputs['logits'], labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        preds = torch.argmax(outputs['logits'], 1)\n        acc.append(sum(preds.cpu() == labels.data.cpu()) / len(preds.cpu()))\n\n        running_loss.append(loss.item()) \n    return np.array(running_loss).mean(), np.array(acc, dtype=float).mean()\n\ndef eval_epoch(model, val_loader, criterion):\n    model.eval()\n    running_loss = []\n    acc = []\n\n    for inputs, labels in val_loader:\n        input_ids = inputs['input_ids'].to(device)\n        attention_mask = inputs['attention_mask'].to(device)\n        token_type_ids = inputs['token_type_ids'].to(device)\n        labels = labels.to(device)\n        with torch.no_grad():\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            loss = criterion(outputs['logits'], labels)\n\n            preds = torch.argmax(outputs['logits'], 1)\n            f1s = f1_score(labels.cpu().data, preds.cpu(), average='weighted')\n            \n            acc.append(f1s)\n                #sum(preds.cpu() == labels.data.cpu()) / len(preds.cpu()))\n            running_loss.append(loss.item())\n\n    return np.array(running_loss).mean(), np.array(acc).mean()\n\ndef train(train_dataset, val_dataset, model, epochs, \n          batch_size, opt, criterion, scheduler=None, save_best=None):\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n\n    history = []\n    best_val_loss = 1000\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} train_acc: {t_acc:0.4f} val_loss {v_loss:0.4f} val_f1 {v_acc:0.4f}\"\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n\n        for epoch in range(epochs):\n            train_loss, acc = fit_epoch(model, train_loader, criterion, opt)\n            \n            val_loss, v_acc = eval_epoch(model, val_loader, criterion)\n            history.append((train_loss, acc, val_loss, v_acc))\n            \n            if scheduler:\n                scheduler.step()\n\n            if save_best:\n              if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save(model.state_dict(), save_best)\n            \n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss, t_acc=acc, v_loss=val_loss, v_acc=v_acc))\n            print('')\n            \n    if save_best:\n      model.load_state_dict(torch.load(save_best, map_location=device))  \n\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:59:25.170136Z","iopub.execute_input":"2022-03-27T09:59:25.170464Z","iopub.status.idle":"2022-03-27T09:59:25.194519Z","shell.execute_reply.started":"2022-03-27T09:59:25.170429Z","shell.execute_reply":"2022-03-27T09:59:25.19375Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Fine tuning the whole model","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\ncriterion = torch.nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.1, \n                                            last_epoch=-1, verbose=True)\n\nhistory = train(train_dataset, val_dataset, model, epochs=10, batch_size=32, \n                opt=optimizer, criterion=criterion, scheduler=scheduler) ","metadata":{"execution":{"iopub.status.busy":"2022-03-27T09:59:25.928169Z","iopub.execute_input":"2022-03-27T09:59:25.928901Z","iopub.status.idle":"2022-03-27T12:22:11.375964Z","shell.execute_reply.started":"2022-03-27T09:59:25.928863Z","shell.execute_reply":"2022-03-27T12:22:11.375263Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-03.\n","output_type":"stream"},{"name":"stderr","text":"epoch:  10%|█         | 1/10 [14:16<2:08:29, 856.57s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-03.\n\nEpoch 001 train_loss: 2.3036 train_acc: 0.1003 val_loss 2.3026 val_f1 0.0229\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [28:33<1:54:15, 856.89s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-04.\n\nEpoch 002 train_loss: 2.3028 train_acc: 0.1001 val_loss 2.3026 val_f1 0.0223\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [42:50<1:39:59, 857.05s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-04.\n\nEpoch 003 train_loss: 2.3026 train_acc: 0.0991 val_loss 2.3026 val_f1 0.0226\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [57:08<1:25:43, 857.27s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-05.\n\nEpoch 004 train_loss: 2.3026 train_acc: 0.0993 val_loss 2.3025 val_f1 0.0225\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [1:11:25<1:11:26, 857.23s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-05.\n\nEpoch 005 train_loss: 2.3025 train_acc: 0.1008 val_loss 2.3025 val_f1 0.0235\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [1:25:41<57:07, 856.76s/it]  ","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-06.\n\nEpoch 006 train_loss: 2.3025 train_acc: 0.1000 val_loss 2.3025 val_f1 0.0225\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [1:39:58<42:50, 856.73s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-06.\n\nEpoch 007 train_loss: 2.3025 train_acc: 0.1010 val_loss 2.3025 val_f1 0.0223\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [1:54:15<28:33, 856.76s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-07.\n\nEpoch 008 train_loss: 2.3025 train_acc: 0.1010 val_loss 2.3025 val_f1 0.0228\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [2:08:30<14:16, 856.32s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-07.\n\nEpoch 009 train_loss: 2.3025 train_acc: 0.1014 val_loss 2.3025 val_f1 0.0234\n\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [2:22:45<00:00, 856.54s/it]","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-08.\n\nEpoch 010 train_loss: 2.3025 train_acc: 0.1014 val_loss 2.3025 val_f1 0.0227\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Fine-tuning is failed","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nids = np.random.randint(1, high=60000, size=1000)\nx_test = np.array(dataset['test']['question_title'])[ids]\ny_test = np.array(dataset['test']['topic'])[ids]\nx_test = tokenizer(x_test.tolist(), padding=\"max_length\", truncation=True, return_tensors='pt')\ntest_dataset = EDataset(x_test, y_test)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\nmodel.eval()\nf1 = []\nfor i, l in test_loader:\n    with torch.no_grad():\n        input_ids = i['input_ids'].to(device)\n        attention_mask = i['attention_mask'].to(device)\n        token_type_ids = i['token_type_ids'].to(device)\n        labels = l.to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n                        token_type_ids=token_type_ids)\n        preds = torch.argmax(outputs['logits'], 1)\n        f1s = f1_score(labels.cpu().data, preds.cpu(), average='weighted')\n        f1.append(f1s)\n        \nprint(sum(f1)/len(f1))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T12:23:13.731272Z","iopub.execute_input":"2022-03-27T12:23:13.732179Z","iopub.status.idle":"2022-03-27T12:23:18.276234Z","shell.execute_reply.started":"2022-03-27T12:23:13.732122Z","shell.execute_reply":"2022-03-27T12:23:18.27526Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"0.015390935479702888\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Transfer learning with layers freezing","metadata":{}},{"cell_type":"code","source":"config = ElectraConfig()\ntokenizer = ElectraTokenizer.from_pretrained(TOKENIZER_NAME)\nmodel = ElectraForSequenceClassification.from_pretrained(TOKENIZER_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T12:27:13.634253Z","iopub.execute_input":"2022-03-27T12:27:13.634799Z","iopub.status.idle":"2022-03-27T12:27:16.914347Z","shell.execute_reply.started":"2022-03-27T12:27:13.634762Z","shell.execute_reply":"2022-03-27T12:27:16.913586Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.bias', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight', 'generator_lm_head.weight']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.parameters():\n      param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-03-27T12:28:34.678495Z","iopub.execute_input":"2022-03-27T12:28:34.678747Z","iopub.status.idle":"2022-03-27T12:28:34.684651Z","shell.execute_reply.started":"2022-03-27T12:28:34.678719Z","shell.execute_reply":"2022-03-27T12:28:34.683696Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.classifier.dense = torch.nn.Linear(256, 64)\nmodel.classifier.out_proj = torch.nn.Sequential(\n    torch.nn.LeakyReLU(),\n    torch.nn.Linear(64, 10))\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T12:28:46.055813Z","iopub.execute_input":"2022-03-27T12:28:46.05607Z","iopub.status.idle":"2022-03-27T12:28:46.096352Z","shell.execute_reply.started":"2022-03-27T12:28:46.05604Z","shell.execute_reply":"2022-03-27T12:28:46.095562Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"ElectraForSequenceClassification(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n      (position_embeddings): Embedding(512, 128)\n      (token_type_embeddings): Embedding(2, 128)\n      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): ElectraClassificationHead(\n    (dense): Linear(in_features=256, out_features=64, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Sequential(\n      (0): LeakyReLU(negative_slope=0.01)\n      (1): Linear(in_features=64, out_features=10, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"params_to_update = [param for param in model.classifier.parameters()]\noptimizer = torch.optim.AdamW(params_to_update, lr=0.001)\ncriterion = torch.nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, gamma=0.2, \n                                            last_epoch=-1, verbose=True)\n\nhistory = train(train_dataset, val_dataset, model, epochs=10, batch_size=32, \n                opt=optimizer, criterion=criterion) \n# what a shame i forgot to pass scheduler parameter","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:00:21.29432Z","iopub.execute_input":"2022-03-27T13:00:21.29459Z","iopub.status.idle":"2022-03-27T13:54:03.819045Z","shell.execute_reply.started":"2022-03-27T13:00:21.294561Z","shell.execute_reply":"2022-03-27T13:54:03.818349Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-03.\n","output_type":"stream"},{"name":"stderr","text":"epoch:  10%|█         | 1/10 [05:22<48:18, 322.05s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 001 train_loss: 1.7281 train_acc: 0.4116 val_loss 1.4979 val_f1 0.5000\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [10:44<42:55, 321.99s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 002 train_loss: 1.7248 train_acc: 0.4133 val_loss 1.4785 val_f1 0.5375\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [16:06<37:33, 322.00s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 003 train_loss: 1.7189 train_acc: 0.4155 val_loss 1.4888 val_f1 0.5177\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [21:28<32:12, 322.13s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 004 train_loss: 1.7218 train_acc: 0.4153 val_loss 1.4612 val_f1 0.5397\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [26:50<26:51, 322.24s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 005 train_loss: 1.7202 train_acc: 0.4156 val_loss 1.4429 val_f1 0.5467\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [32:13<21:29, 322.30s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 006 train_loss: 1.7143 train_acc: 0.4167 val_loss 1.4836 val_f1 0.5305\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [37:35<16:06, 322.31s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 007 train_loss: 1.7137 train_acc: 0.4178 val_loss 1.4699 val_f1 0.5326\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [42:57<10:44, 322.32s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 008 train_loss: 1.7137 train_acc: 0.4177 val_loss 1.4724 val_f1 0.5332\n\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [48:20<05:22, 322.33s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 009 train_loss: 1.7168 train_acc: 0.4178 val_loss 1.4630 val_f1 0.5102\n\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [53:42<00:00, 322.25s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 010 train_loss: 1.7134 train_acc: 0.4167 val_loss 1.4351 val_f1 0.5363\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nf1 = []\nfor i, l in test_loader:\n    with torch.no_grad():\n        input_ids = i['input_ids'].to(device)\n        attention_mask = i['attention_mask'].to(device)\n        token_type_ids = i['token_type_ids'].to(device)\n        labels = l.to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n                        token_type_ids=token_type_ids)\n        preds = torch.argmax(outputs['logits'], 1)\n        f1s = f1_score(labels.cpu().data, preds.cpu(), average='weighted')\n        f1.append(f1s)\n        \nprint(sum(f1)/len(f1))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T12:59:26.445894Z","iopub.execute_input":"2022-03-27T12:59:26.44615Z","iopub.status.idle":"2022-03-27T12:59:30.238659Z","shell.execute_reply.started":"2022-03-27T12:59:26.446121Z","shell.execute_reply":"2022-03-27T12:59:30.237889Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"0.5255830394329934\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Well this looks better","metadata":{}},{"cell_type":"markdown","source":"## Results\n\nI spent much time on fine-tuning whole model, i tried Adam and AdamW optimizers (they say, AdamW is more suitable for BERT-based models), also learning rate scheduler. In first case, it did not impore learning process at all. I guess i had to train Electra in another way, as it after training it performed even worse, than before training\n\nIn case with freezing weights, it trained much faster and performed quite well. I freezed all parameters of model, except the classifier layers. ","metadata":{}}]}